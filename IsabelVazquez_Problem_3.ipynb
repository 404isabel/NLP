{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IsabelVazquez_Problem_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/404isabel/NLP/blob/master/IsabelVazquez_Problem_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy8PLXt7xA8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aI4bPHwMA8M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "9ebae6e1-7417-4525-9228-5a1f468045f1"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnQ3u3PMzabV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_text=\"Just A Rather Very Intelligent System a.k.a JARVIS is created by Tony Stark natural-language and a sophisticated artificial intelligence user interface computer system, named after Edwin Jarvis, the butler who worked for Howard Stark. Though its primary duty is to automate Stark’s Malibu estate, the lifelike program fulfills many other needs for Stark, like being an information source for him, a diagnostic tool, a consultant and a voice of reason in Stark’s life. It was also responsible to provide security for Tony Stark's Mansion and Stark Tower. After creating the Mark II armor, Stark uploaded JARVIS into all of the Iron Man Armors, as well as allowing him to interact with the other Avengers, giving them valuable information during combat. JARVIS may be the one intellect Stark feels most comfortable opening up to. JARVIS can object to Stark’s commands if necessary. JARVIS speaks with a refined British accent, and is capable of back talk, sarcasm and condescension. During the Ultron Offensive, JARVIS was destroyed by Ultron, although his remaining programming codes unknowingly continued to thwart Ultron's plans of gaining access to nuclear missiles. His remains were found by Stark, who uploaded them into a synthetic body made of vibranium and, in conjunction with Ultron's personality and an Infinity Stone. JARVIS' duties were then taken over by FRIDAY. \""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ON6ZHNigqxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_text=\"JARVIS is created by Tony Stark natural-language and a sophisticated artificial intelligence user interface computer system, named after Edwin Jarvis\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlAY1DBrwZbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Replace invalid or useless characters\n",
        "input_text=input_text.replace(\"’\",\"'\")\n",
        "#input_text=input_text.replace(\".\",\"\") \n",
        "input_text=input_text.replace(\",\",\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf0PkSrHLDIj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "ca8fbabd-ca47-4786-ece8-fab6570f2f7d"
      },
      "source": [
        "#tags = nltk.pos_tag(input_text.split())\n",
        "tags = nltk.pos_tag(tbt.tokenize(input_text))\n",
        "print(len(tags))\n",
        "print(tags)\n",
        "a=tags[0]\n",
        "b=a[1]\n",
        "print(b)"
      ],
      "execution_count": 393,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "225\n",
            "[('Just', 'RB'), ('A', 'DT'), ('Rather', 'RB'), ('Very', 'NNP'), ('Intelligent', 'NNP'), ('System', 'NNP'), ('a.k.a', 'JJ'), ('JARVIS', 'NNP'), ('is', 'VBZ'), ('created', 'VBN'), ('by', 'IN'), ('Tony', 'NNP'), ('Stark', 'NNP'), ('natural-language', 'NN'), ('and', 'CC'), ('a', 'DT'), ('sophisticated', 'JJ'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('user', 'NN'), ('interface', 'NN'), ('computer', 'NN'), ('system', 'NN'), ('named', 'VBN'), ('after', 'IN'), ('Edwin', 'NNP'), ('Jarvis', 'NNP'), ('the', 'DT'), ('butler', 'NN'), ('who', 'WP'), ('worked', 'VBD'), ('for', 'IN'), ('Howard', 'NNP'), ('Stark.', 'NNP'), ('Though', 'NNP'), ('its', 'PRP$'), ('primary', 'JJ'), ('duty', 'NN'), ('is', 'VBZ'), ('to', 'TO'), ('automate', 'VB'), ('Stark', 'NNP'), (\"'s\", 'POS'), ('Malibu', 'NNP'), ('estate', 'NN'), ('the', 'DT'), ('lifelike', 'NN'), ('program', 'NN'), ('fulfills', 'NNS'), ('many', 'JJ'), ('other', 'JJ'), ('needs', 'NNS'), ('for', 'IN'), ('Stark', 'NNP'), ('like', 'IN'), ('being', 'VBG'), ('an', 'DT'), ('information', 'NN'), ('source', 'NN'), ('for', 'IN'), ('him', 'PRP'), ('a', 'DT'), ('diagnostic', 'JJ'), ('tool', 'NN'), ('a', 'DT'), ('consultant', 'NN'), ('and', 'CC'), ('a', 'DT'), ('voice', 'NN'), ('of', 'IN'), ('reason', 'NN'), ('in', 'IN'), ('Stark', 'NNP'), (\"'s\", 'POS'), ('life.', 'NN'), ('It', 'PRP'), ('was', 'VBD'), ('also', 'RB'), ('responsible', 'JJ'), ('to', 'TO'), ('provide', 'VB'), ('security', 'NN'), ('for', 'IN'), ('Tony', 'NNP'), ('Stark', 'NNP'), (\"'s\", 'POS'), ('Mansion', 'NNP'), ('and', 'CC'), ('Stark', 'NNP'), ('Tower.', 'NNP'), ('After', 'IN'), ('creating', 'VBG'), ('the', 'DT'), ('Mark', 'NNP'), ('II', 'NNP'), ('armor', 'NN'), ('Stark', 'NNP'), ('uploaded', 'VBD'), ('JARVIS', 'NNP'), ('into', 'IN'), ('all', 'DT'), ('of', 'IN'), ('the', 'DT'), ('Iron', 'NNP'), ('Man', 'NNP'), ('Armors', 'NNPS'), ('as', 'RB'), ('well', 'RB'), ('as', 'IN'), ('allowing', 'VBG'), ('him', 'PRP'), ('to', 'TO'), ('interact', 'VB'), ('with', 'IN'), ('the', 'DT'), ('other', 'JJ'), ('Avengers', 'NNPS'), ('giving', 'VBG'), ('them', 'PRP'), ('valuable', 'JJ'), ('information', 'NN'), ('during', 'IN'), ('combat.', 'NN'), ('JARVIS', 'NNP'), ('may', 'MD'), ('be', 'VB'), ('the', 'DT'), ('one', 'CD'), ('intellect', 'NN'), ('Stark', 'NNP'), ('feels', 'VBZ'), ('most', 'RBS'), ('comfortable', 'JJ'), ('opening', 'VBG'), ('up', 'RP'), ('to.', 'JJ'), ('JARVIS', 'NNP'), ('can', 'MD'), ('object', 'VB'), ('to', 'TO'), ('Stark', 'NNP'), (\"'s\", 'POS'), ('commands', 'NNS'), ('if', 'IN'), ('necessary.', 'JJ'), ('JARVIS', 'NNP'), ('speaks', 'VBZ'), ('with', 'IN'), ('a', 'DT'), ('refined', 'JJ'), ('British', 'JJ'), ('accent', 'NN'), ('and', 'CC'), ('is', 'VBZ'), ('capable', 'JJ'), ('of', 'IN'), ('back', 'JJ'), ('talk', 'NN'), ('sarcasm', 'NN'), ('and', 'CC'), ('condescension.', 'NN'), ('During', 'IN'), ('the', 'DT'), ('Ultron', 'NNP'), ('Offensive', 'NNP'), ('JARVIS', 'NNP'), ('was', 'VBD'), ('destroyed', 'VBN'), ('by', 'IN'), ('Ultron', 'NNP'), ('although', 'IN'), ('his', 'PRP$'), ('remaining', 'VBG'), ('programming', 'VBG'), ('codes', 'NNS'), ('unknowingly', 'RB'), ('continued', 'VBD'), ('to', 'TO'), ('thwart', 'VB'), ('Ultron', 'NNP'), (\"'s\", 'POS'), ('plans', 'NNS'), ('of', 'IN'), ('gaining', 'VBG'), ('access', 'NN'), ('to', 'TO'), ('nuclear', 'JJ'), ('missiles.', 'VB'), ('His', 'PRP$'), ('remains', 'NNS'), ('were', 'VBD'), ('found', 'VBN'), ('by', 'IN'), ('Stark', 'NNP'), ('who', 'WP'), ('uploaded', 'VBD'), ('them', 'PRP'), ('into', 'IN'), ('a', 'DT'), ('synthetic', 'JJ'), ('body', 'NN'), ('made', 'VBD'), ('of', 'IN'), ('vibranium', 'NN'), ('and', 'CC'), ('in', 'IN'), ('conjunction', 'NN'), ('with', 'IN'), ('Ultron', 'NNP'), (\"'s\", 'POS'), ('personality', 'NN'), ('and', 'CC'), ('an', 'DT'), ('Infinity', 'NNP'), ('Stone.', 'NNP'), ('JARVIS', 'NNP'), (\"'\", 'POS'), ('duties', 'NNS'), ('were', 'VBD'), ('then', 'RB'), ('taken', 'VBN'), ('over', 'RP'), ('by', 'IN'), ('FRIDAY', 'NNP'), ('.', '.')]\n",
            "RB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYuCr6jbMfBm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2a7f8592-5cdd-4d25-bf52-666355b52c37"
      },
      "source": [
        "texto_prueba=\"Tony Stark\"\n",
        "t=nltk.pos_tag([texto_prueba])\n",
        "a=(t[0])\n",
        "a[1]\n",
        "#t2=\"is created by Tony Stark\"\n",
        "#print(nltk.pos_tag(t2.split()))"
      ],
      "execution_count": 394,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NN'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 394
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sVHXVtwR6iY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c620d502-bdda-41f4-9c27-b34d179e1920"
      },
      "source": [
        "from nltk import TreebankWordTokenizer\n",
        "tbt = TreebankWordTokenizer()\n",
        "tokens=tbt.tokenize(input_text) \n",
        "print(len(tokens))\n",
        "#tokens"
      ],
      "execution_count": 395,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftRLi6FIcBAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This function get the next Linguistic Unit\n",
        "#Quiere decir que no coje adjetivos, o pronombres sueltos, sino que identifica una palabra que tenga sentido\n",
        "def getNextWords_old(tokens,i,n):\n",
        "  words=[]\n",
        "  words.append(tokens[i+n])\n",
        "  return words\n",
        "\n",
        "def getType(i):\n",
        "  \n",
        "  tag=tags[i]\n",
        "  wordType=tag[1] #NNP, NN, JJ, etc...\n",
        "  return wordType\n",
        "\n",
        "def getNextLinguisticUnits(tokens,i,n):\n",
        "  words=[]\n",
        "  \n",
        "  #The first word\n",
        "  word=tokens[i+n]\n",
        "  \n",
        "  #Detect the type of word\n",
        "  wordType=getType(i+n) \n",
        "  pos=i+n+1\n",
        "  linguisticUnit=word\n",
        "  punto=False\n",
        "\n",
        "  #Create and add the linguistic units\n",
        "  prep=\"\"\n",
        "  if wordType in [\"IN\", \"DT\",\"MD\",\"TO\",\"POS\"]:\n",
        "    prep=linguisticUnit\n",
        "    #Search the next word        \n",
        "    while wordType in [\"IN\", \"DT\",\"MD\",\"TO\",\"POS\"] and pos<len(tokens):\n",
        "      \n",
        "      w=tokens[pos]      \n",
        "      wordType=getType(pos)\n",
        "      \n",
        "      if wordType in [\"IN\", \"DT\",\"MD\",\"TO\",\"POS\"]:        \n",
        "        #linguisticUnit+=\" \"+w\n",
        "        prep+=\" \"+w               \n",
        "        pos=pos+1\n",
        "    prep+=\" \"        \n",
        "  \n",
        "  if prep!=\"\":\n",
        "    linguisticUnit=tokens[pos]\n",
        "    wordType=getType(pos)\n",
        "\n",
        "  if wordType == 'JJ': \n",
        "    if prep!=\"\":\n",
        "      pos=pos+1 \n",
        "    while wordType == 'JJ' and pos+1<len(tokens)-1:\n",
        "      #pos+=1\n",
        "      adj=tokens[pos]      \n",
        "      wordType=getType(pos)\n",
        "      if wordType == 'JJ':\n",
        "        linguisticUnit+=\" \"+adj \n",
        "        pos+=1\n",
        "    \n",
        "    w=tokens[pos]      \n",
        "    wordType=getType(pos)\n",
        "    \n",
        "    if wordType in [\"NN\",\"NNS\"]:\n",
        "        linguisticUnit+=\" \"+w\n",
        "    \n",
        "    #print(linguisticUnit)     \n",
        "    words.append(prep+linguisticUnit) \n",
        "  \n",
        "  elif wordType == 'NNP':  \n",
        "    if prep!=\"\":\n",
        "      pos=pos+1 \n",
        "    while wordType == 'NNP' and pos<len(tokens)-1:\n",
        "      w=tokens[pos]  \n",
        "      #print(w)    \n",
        "      wordType=getType(pos)      \n",
        "      if wordType == 'NNP':\n",
        "        linguisticUnit+=\" \"+w                 \n",
        "        pos=pos+1        \n",
        "    words.append(prep+linguisticUnit)\n",
        "\n",
        "  elif wordType in [\"NN\",\"NNS\"]:    \n",
        "    #appends the word    \n",
        "    #print(prep+linguisticUnit)\n",
        "    words.append(prep+linguisticUnit)\n",
        "    #pos=pos+1\n",
        "\n",
        "    if prep!=\"\":\n",
        "      pos=pos+1 \n",
        "\n",
        "    while wordType in [\"NN\",\"NNS\"] and pos<len(tokens)-1:\n",
        "      w=tokens[pos]      \n",
        "      wordType=getType(pos)      \n",
        "      if wordType in [\"NN\",\"NNS\"]:\n",
        "        linguisticUnit+=\" \"+w\n",
        "        words.append(linguisticUnit)          \n",
        "        pos=pos+1\n",
        "     \n",
        "  else:\n",
        "    #It's a linguistic unit\n",
        "    words.append(prep+linguisticUnit)\n",
        "   \n",
        "\n",
        "  return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i6Xu22QSBGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creates a n-gram\n",
        "#params\n",
        "#tokens: tokens of words\n",
        "#n: n=3 (trigram) or n=2 (bigram)\n",
        "def createNgram(tokens,n):\n",
        "  ngrams = {}\n",
        "  for i in range(len(tokens)-n):\n",
        "      k=()\n",
        "      if n==3: \n",
        "        k = (tokens[i],tokens[i+1],tokens[i+2])          \n",
        "      elif n==2:\n",
        "        k = (tokens[i],tokens[i+1])\n",
        "      if k not in ngrams: #if the bigram doesn't exists, it is created\n",
        "          ngrams[k] = []\n",
        "      \n",
        "      words=getNextLinguisticUnits(tokens,i,n) #get the next 'words'   \n",
        "      for word in words: ngrams[k].append(word) #append the words to the n-gram                                    \n",
        "  return ngrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jkWbRHAZ1Yk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ngrams=createNgram(tokens,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0yfGUDdZ6pi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "f7834c87-e749-4741-ac41-d97d3899ca92"
      },
      "source": [
        "print(ngrams)"
      ],
      "execution_count": 417,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{('Just', 'A', 'Rather'): ['Very Intelligent System'], ('A', 'Rather', 'Very'): ['Intelligent System'], ('Rather', 'Very', 'Intelligent'): ['System'], ('Very', 'Intelligent', 'System'): ['aka'], ('Intelligent', 'System', 'a.k.a'): ['JARVIS'], ('System', 'a.k.a', 'JARVIS'): ['is'], ('a.k.a', 'JARVIS', 'is'): ['created'], ('JARVIS', 'is', 'created'): ['by Tony Stark'], ('is', 'created', 'by'): ['Tony Stark'], ('created', 'by', 'Tony'): ['Stark'], ('by', 'Tony', 'Stark'): ['natural-language'], ('Tony', 'Stark', 'natural-language'): ['and'], ('Stark', 'natural-language', 'and'): ['a sophisticated artificial intelligence'], ('natural-language', 'and', 'a'): ['sophisticated artificial intelligence'], ('and', 'a', 'sophisticated'): ['artificial intelligence'], ('a', 'sophisticated', 'artificial'): ['intelligence', 'intelligence user', 'intelligence user interface', 'intelligence user interface computer', 'intelligence user interface computer system'], ('sophisticated', 'artificial', 'intelligence'): ['user', 'user interface', 'user interface computer', 'user interface computer system'], ('artificial', 'intelligence', 'user'): ['interface', 'interface computer', 'interface computer system'], ('intelligence', 'user', 'interface'): ['computer', 'computer system'], ('user', 'interface', 'computer'): ['system'], ('interface', 'computer', 'system'): ['named'], ('computer', 'system', 'named'): ['after Edwin Jarvis'], ('system', 'named', 'after'): ['Edwin Jarvis'], ('named', 'after', 'Edwin'): ['Jarvis'], ('after', 'Edwin', 'Jarvis'): ['the butler'], ('Edwin', 'Jarvis', 'the'): ['butler'], ('Jarvis', 'the', 'butler'): ['who'], ('the', 'butler', 'who'): ['worked'], ('butler', 'who', 'worked'): ['for Howard Stark. Though'], ('who', 'worked', 'for'): ['Howard Stark. Though'], ('worked', 'for', 'Howard'): ['Stark. Though'], ('for', 'Howard', 'Stark.'): ['Though'], ('Howard', 'Stark.', 'Though'): ['its'], ('Stark.', 'Though', 'its'): ['primary duty'], ('Though', 'its', 'primary'): ['duty'], ('its', 'primary', 'duty'): ['is'], ('primary', 'duty', 'is'): ['to automate'], ('duty', 'is', 'to'): ['automate'], ('is', 'to', 'automate'): ['Stark'], ('to', 'automate', 'Stark'): [\"'s Malibu\"], ('automate', 'Stark', \"'s\"): ['Malibu'], ('Stark', \"'s\", 'Malibu'): ['estate'], (\"'s\", 'Malibu', 'estate'): ['the lifelike', 'lifelike program', 'lifelike program fulfills'], ('Malibu', 'estate', 'the'): ['lifelike', 'lifelike program', 'lifelike program fulfills'], ('estate', 'the', 'lifelike'): ['program', 'program fulfills'], ('the', 'lifelike', 'program'): ['fulfills'], ('lifelike', 'program', 'fulfills'): ['many other needs'], ('program', 'fulfills', 'many'): ['other needs'], ('fulfills', 'many', 'other'): ['needs'], ('many', 'other', 'needs'): ['for Stark'], ('other', 'needs', 'for'): ['Stark'], ('needs', 'for', 'Stark'): ['like being'], ('for', 'Stark', 'like'): ['being'], ('Stark', 'like', 'being'): ['an information', 'information source'], ('like', 'being', 'an'): ['information', 'information source'], ('being', 'an', 'information'): ['source'], ('an', 'information', 'source'): ['for him'], ('information', 'source', 'for'): ['him'], ('source', 'for', 'him'): ['a diagnostic tool'], ('for', 'him', 'a'): ['diagnostic tool'], ('him', 'a', 'diagnostic'): ['tool'], ('a', 'diagnostic', 'tool'): ['a consultant'], ('diagnostic', 'tool', 'a'): ['consultant'], ('tool', 'a', 'consultant'): ['and'], ('a', 'consultant', 'and'): ['a voice'], ('consultant', 'and', 'a'): ['voice'], ('and', 'a', 'voice'): ['of reason'], ('a', 'voice', 'of'): ['reason'], ('voice', 'of', 'reason'): ['in Stark'], ('of', 'reason', 'in'): ['Stark'], ('reason', 'in', 'Stark'): [\"'s life.\"], ('in', 'Stark', \"'s\"): ['life.'], ('Stark', \"'s\", 'life.'): ['It'], (\"'s\", 'life.', 'It'): ['was'], ('life.', 'It', 'was'): ['also'], ('It', 'was', 'also'): ['responsible'], ('was', 'also', 'responsible'): ['to provide'], ('also', 'responsible', 'to'): ['provide'], ('responsible', 'to', 'provide'): ['security'], ('to', 'provide', 'security'): ['for Tony Stark'], ('provide', 'security', 'for'): ['Tony Stark'], ('security', 'for', 'Tony'): ['Stark'], ('for', 'Tony', 'Stark'): [\"'s Mansion\"], ('Tony', 'Stark', \"'s\"): ['Mansion'], ('Stark', \"'s\", 'Mansion'): ['and'], (\"'s\", 'Mansion', 'and'): ['Stark Tower.'], ('Mansion', 'and', 'Stark'): ['Tower.'], ('and', 'Stark', 'Tower.'): ['After creating'], ('Stark', 'Tower.', 'After'): ['creating'], ('Tower.', 'After', 'creating'): ['the Mark II'], ('After', 'creating', 'the'): ['Mark II'], ('creating', 'the', 'Mark'): ['II'], ('the', 'Mark', 'II'): ['armor'], ('Mark', 'II', 'armor'): ['Stark'], ('II', 'armor', 'Stark'): ['uploaded'], ('armor', 'Stark', 'uploaded'): ['JARVIS'], ('Stark', 'uploaded', 'JARVIS'): ['into all of the Iron Man'], ('uploaded', 'JARVIS', 'into'): ['all of the Iron Man'], ('JARVIS', 'into', 'all'): ['of the Iron Man'], ('into', 'all', 'of'): ['the Iron Man'], ('all', 'of', 'the'): ['Iron Man'], ('of', 'the', 'Iron'): ['Man'], ('the', 'Iron', 'Man'): ['Armors'], ('Iron', 'Man', 'Armors'): ['as'], ('Man', 'Armors', 'as'): ['well'], ('Armors', 'as', 'well'): ['as allowing'], ('as', 'well', 'as'): ['allowing'], ('well', 'as', 'allowing'): ['him'], ('as', 'allowing', 'him'): ['to interact'], ('allowing', 'him', 'to'): ['interact'], ('him', 'to', 'interact'): ['with the other'], ('to', 'interact', 'with'): ['the other'], ('interact', 'with', 'the'): ['other'], ('with', 'the', 'other'): ['Avengers'], ('the', 'other', 'Avengers'): ['giving'], ('other', 'Avengers', 'giving'): ['them'], ('Avengers', 'giving', 'them'): ['valuable information'], ('giving', 'them', 'valuable'): ['information'], ('them', 'valuable', 'information'): ['during combat.'], ('valuable', 'information', 'during'): ['combat.'], ('information', 'during', 'combat.'): ['JARVIS'], ('during', 'combat.', 'JARVIS'): ['may be'], ('combat.', 'JARVIS', 'may'): ['be'], ('JARVIS', 'may', 'be'): ['the one'], ('may', 'be', 'the'): ['one'], ('be', 'the', 'one'): ['intellect'], ('the', 'one', 'intellect'): ['Stark'], ('one', 'intellect', 'Stark'): ['feels'], ('intellect', 'Stark', 'feels'): ['most'], ('Stark', 'feels', 'most'): ['comfortable'], ('feels', 'most', 'comfortable'): ['opening'], ('most', 'comfortable', 'opening'): ['up'], ('comfortable', 'opening', 'up'): ['to'], ('opening', 'up', 'to.'): ['JARVIS'], ('up', 'to.', 'JARVIS'): ['can object'], ('to.', 'JARVIS', 'can'): ['object'], ('JARVIS', 'can', 'object'): ['to Stark'], ('can', 'object', 'to'): ['Stark'], ('object', 'to', 'Stark'): [\"'s commands\"], ('to', 'Stark', \"'s\"): ['commands'], ('Stark', \"'s\", 'commands'): ['if necessary'], (\"'s\", 'commands', 'if'): ['necessary'], ('commands', 'if', 'necessary.'): ['JARVIS'], ('if', 'necessary.', 'JARVIS'): ['speaks'], ('necessary.', 'JARVIS', 'speaks'): ['with a refined British accent'], ('JARVIS', 'speaks', 'with'): ['a refined British accent'], ('speaks', 'with', 'a'): ['refined British accent'], ('with', 'a', 'refined'): ['British accent'], ('a', 'refined', 'British'): ['accent'], ('refined', 'British', 'accent'): ['and'], ('British', 'accent', 'and'): ['is'], ('accent', 'and', 'is'): ['capable'], ('and', 'is', 'capable'): ['of back talk'], ('is', 'capable', 'of'): ['back talk'], ('capable', 'of', 'back'): ['talk', 'talk sarcasm'], ('of', 'back', 'talk'): ['sarcasm'], ('back', 'talk', 'sarcasm'): ['and'], ('talk', 'sarcasm', 'and'): ['condescension.'], ('sarcasm', 'and', 'condescension.'): ['During the Ultron Offensive JARVIS'], ('and', 'condescension.', 'During'): ['the Ultron Offensive JARVIS'], ('condescension.', 'During', 'the'): ['Ultron Offensive JARVIS'], ('During', 'the', 'Ultron'): ['Offensive JARVIS'], ('the', 'Ultron', 'Offensive'): ['JARVIS'], ('Ultron', 'Offensive', 'JARVIS'): ['was'], ('Offensive', 'JARVIS', 'was'): ['destroyed'], ('JARVIS', 'was', 'destroyed'): ['by Ultron'], ('was', 'destroyed', 'by'): ['Ultron'], ('destroyed', 'by', 'Ultron'): ['although his'], ('by', 'Ultron', 'although'): ['his'], ('Ultron', 'although', 'his'): ['remaining'], ('although', 'his', 'remaining'): ['programming'], ('his', 'remaining', 'programming'): ['codes'], ('remaining', 'programming', 'codes'): ['unknowingly'], ('programming', 'codes', 'unknowingly'): ['continued'], ('codes', 'unknowingly', 'continued'): ['to thwart'], ('unknowingly', 'continued', 'to'): ['thwart'], ('continued', 'to', 'thwart'): ['Ultron'], ('to', 'thwart', 'Ultron'): [\"'s plans\"], ('thwart', 'Ultron', \"'s\"): ['plans'], ('Ultron', \"'s\", 'plans'): ['of gaining'], (\"'s\", 'plans', 'of'): ['gaining'], ('plans', 'of', 'gaining'): ['access'], ('of', 'gaining', 'access'): ['to nuclear'], ('gaining', 'access', 'to'): ['nuclear'], ('access', 'to', 'nuclear'): ['missiles.'], ('to', 'nuclear', 'missiles.'): ['His'], ('nuclear', 'missiles.', 'His'): ['remains'], ('missiles.', 'His', 'remains'): ['were'], ('His', 'remains', 'were'): ['found'], ('remains', 'were', 'found'): ['by Stark'], ('were', 'found', 'by'): ['Stark'], ('found', 'by', 'Stark'): ['who'], ('by', 'Stark', 'who'): ['uploaded'], ('Stark', 'who', 'uploaded'): ['them'], ('who', 'uploaded', 'them'): ['into a synthetic body'], ('uploaded', 'them', 'into'): ['a synthetic body'], ('them', 'into', 'a'): ['synthetic body'], ('into', 'a', 'synthetic'): ['body'], ('a', 'synthetic', 'body'): ['made'], ('synthetic', 'body', 'made'): ['of vibranium'], ('body', 'made', 'of'): ['vibranium'], ('made', 'of', 'vibranium'): ['and'], ('of', 'vibranium', 'and'): ['in conjunction'], ('vibranium', 'and', 'in'): ['conjunction'], ('and', 'in', 'conjunction'): ['with Ultron'], ('in', 'conjunction', 'with'): ['Ultron'], ('conjunction', 'with', 'Ultron'): [\"'s personality\"], ('with', 'Ultron', \"'s\"): ['personality'], ('Ultron', \"'s\", 'personality'): ['and'], (\"'s\", 'personality', 'and'): ['an Infinity Stone. JARVIS'], ('personality', 'and', 'an'): ['Infinity Stone. JARVIS'], ('and', 'an', 'Infinity'): ['Stone. JARVIS'], ('an', 'Infinity', 'Stone.'): ['JARVIS'], ('Infinity', 'Stone.', 'JARVIS'): [\"' duties\"], ('Stone.', 'JARVIS', \"'\"): ['duties'], ('JARVIS', \"'\", 'duties'): ['were'], (\"'\", 'duties', 'were'): ['then'], ('duties', 'were', 'then'): ['taken'], ('were', 'then', 'taken'): ['over'], ('then', 'taken', 'over'): ['by FRIDAY'], ('taken', 'over', 'by'): ['FRIDAY'], ('over', 'by', 'FRIDAY'): ['.']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2No_CHHzfvvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predictNextWord(input): \n",
        "  if len(input)<2:\n",
        "    print(\"At least two words are required\")\n",
        "  else:\n",
        "    inputTokens=tbt.tokenize(input)\n",
        "    #if the sentence has only two words\n",
        "    if len(inputTokens)==2:\n",
        "      ngrams=createNgram(tokens,2) #Creates de bi-gram\n",
        "      lastTokens=inputTokens[len(inputTokens)-2:len(inputTokens)] \n",
        "      k = (lastTokens[0],lastTokens[1])  \n",
        "      try:          \n",
        "         return ngrams[k]\n",
        "      except:\n",
        "         return [] #Nothing could be predicted\n",
        "    else:\n",
        "      ngrams=createNgram(tokens,3) #Creates the tri-gram\n",
        "      lastTokens=inputTokens[len(inputTokens)-3:len(inputTokens)] \n",
        "      k = (lastTokens[0],lastTokens[1],lastTokens[2])      \n",
        "      try:      \n",
        "        return ngrams[k]\n",
        "      except:\n",
        "        #if nothing is foud, tries with a bi-gram\n",
        "        ngrams=createNgram(tokens,2)\n",
        "        k = (lastTokens[1],lastTokens[2])        \n",
        "        try:\n",
        "          return ngrams[k]\n",
        "        except:\n",
        "          return [] #Nothing could be predicte\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQLkZKlOd8rt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a1a286b8-f4d4-4c7b-f2cc-cc3298c9940a"
      },
      "source": [
        "a=\"asdf\"\n",
        "b=a.replace(\".\",\"\")\n",
        "print(b)"
      ],
      "execution_count": 432,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "asdf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23HCgfqyaME7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "e13741e6-7950-48f1-ba9f-cf21519e3b4b"
      },
      "source": [
        "input1=\"JARVIS was destroyed\"\n",
        "input2=\"JARVIS is created by\"\n",
        "input3=\"JARVIS can object to Stark's\"\n",
        "input4=\"a sophisticated artificial\"\n",
        "print(predictNextWord(input1))\n",
        "print(predictNextWord(input2))\n",
        "print(predictNextWord(input3))\n",
        "print(predictNextWord(input4))\n"
      ],
      "execution_count": 463,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['by Ultron']\n",
            "['Tony Stark']\n",
            "['commands']\n",
            "['intelligence', 'intelligence user', 'intelligence user interface', 'intelligence user interface computer', 'intelligence user interface computer system']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6QwTsFsgqBM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "c31b7caa-914d-4a99-9f8d-f217ca3010ee"
      },
      "source": [
        "input4=\"sophisticated artificial intelligence\"\n",
        "print(predictNextWord(input4))\n",
        "input5=\"like being an information\"\n",
        "print(predictNextWord(input5))\n",
        "input6=\"Mansion and Stark Tower\"\n",
        "print(predictNextWord(input6))\n",
        "input7=\"information during\"\n",
        "print(predictNextWord(input7)) #Falta eliminar los puntos y final\n",
        "input8=\"JARVIS speaks\"\n",
        "print(predictNextWord(input8))\n"
      ],
      "execution_count": 467,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['user', 'user interface', 'user interface computer', 'user interface computer system']\n",
            "['source']\n",
            "[]\n",
            "['combat.']\n",
            "['with a refined British accent']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T2dfwjpYFLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ngram_probabilities =  {}\n",
        "for k,words in ngrams.items():\n",
        "    if len(set(words)) > 1:\n",
        "        d = {}\n",
        "        n = 0\n",
        "        for w in words:\n",
        "            if w not in d:\n",
        "                d[w] = 0\n",
        "            d[w] +=1\n",
        "            n +=1\n",
        "        for w,c in d.items():\n",
        "            d[w] = float(c)/n\n",
        "        ngram_probabilities[k] = d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YUFhOL-YMgD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "c1f4f856-939c-4124-a604-60aaaecd7a07"
      },
      "source": [
        "print(ngram_probabilities)"
      ],
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{('a', 'sophisticated', 'artificial'): {'intelligence': 0.2, 'intelligence user': 0.2, 'intelligence user interface': 0.2, 'intelligence user interface computer': 0.2, 'intelligence user interface computer system': 0.2}, ('sophisticated', 'artificial', 'intelligence'): {'user': 0.25, 'user interface': 0.25, 'user interface computer': 0.25, 'user interface computer system': 0.25}, ('artificial', 'intelligence', 'user'): {'interface': 0.3333333333333333, 'interface computer': 0.3333333333333333, 'interface computer system': 0.3333333333333333}, ('intelligence', 'user', 'interface'): {'computer': 0.5, 'computer system': 0.5}, (\"'s\", 'Malibu', 'estate'): {'the lifelike': 0.3333333333333333, 'lifelike program': 0.3333333333333333, 'lifelike program fulfills': 0.3333333333333333}, ('Malibu', 'estate', 'the'): {'lifelike': 0.3333333333333333, 'lifelike program': 0.3333333333333333, 'lifelike program fulfills': 0.3333333333333333}, ('estate', 'the', 'lifelike'): {'program': 0.5, 'program fulfills': 0.5}, ('Stark', 'like', 'being'): {'an information': 0.5, 'information source': 0.5}, ('like', 'being', 'an'): {'information': 0.5, 'information source': 0.5}, ('capable', 'of', 'back'): {'talk': 0.5, 'talk sarcasm': 0.5}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgZxegoSYPdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}